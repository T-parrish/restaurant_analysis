import pandas as pd
from data_processing import order
from itertools import chain

from data_processing.util import get_ngram_frequency

from typing import TypeVar, List, Dict

T = TypeVar('T')


def build_order_df(time_map={}, price_map={}) -> pd.DataFrame:
    '''
    Function that takes a reference to a mapping of menu items -> cook time and
    another reference to a mapping of menu items -> price to return
    the processed order dataframe.

    :Param: time_map: Dict[str, int]
    ---------
        Mapping of menu items to cook time

    :Param: price_map: Dict[str, int]
    ---------
        Mapping of price items to cook time

    :returns: pd.DataFrame
    ---------
        Schema:
            'service', 'name', 'items', 'DOW', 'intDOW',
            'Hour', 'orderCount', 'orderValue', 'orderTime'
    '''
    # Takes a time mapping and a price mapping dictionary
    # generates a Dataframe with some derived columns
    o_df = pd.read_json('orders.json')
    o_df['ordered_at'] = o_df['ordered_at'].astype("datetime64")

    # Store the DOW String in a column on the DF for grouping and binning
    o_df['DOW'] = o_df['ordered_at'].apply(lambda x: x.to_pydatetime().strftime('%A'))
    # Int version of DOW
    o_df['intDOW'] = o_df['ordered_at'].apply(lambda x: x.to_pydatetime().weekday())

    # Store the Hour integer in a column on the DF for grouping and binning
    o_df['Hour'] = o_df['ordered_at'].apply(lambda x: x.to_pydatetime().strftime('%H')).astype(int)

    # Total number of items per order
    o_df['item count'] = o_df['items'].apply(lambda x: sum([obj.get('quantity', 0) for obj in x]))

    # Total revenue per order
    o_df['order value (usd)'] = (
        o_df['items'].apply(
            lambda x: sum([obj.get('paid_per_unit', 0) * obj.get('quantity', 0) for obj in x]) / 100)
    )

    o_df['order time (min)'] = o_df['items'].apply(lambda x: order.get_order_cook_time(x, time_map, price_map) / 60)

    first_order = o_df['ordered_at'].min()
    last_order = o_df['ordered_at'].max()
    print(f'First order of set: {first_order}\nLast order of set: {last_order}')

    o_df = o_df.drop('ordered_at', axis=1)

    return o_df


def build_menu_df() -> pd.DataFrame:
    '''
        Function that returns a menu dataframe from 'items.json' file.

        :Returns: pd.DataFrame
        ---------
            Schema:
                'name', 'cook_time', 'price_per_unit'
    '''
    return pd.read_json('items.json')


def build_menu_perf_df(o_df: pd.DataFrame, m_df: pd.DataFrame) -> pd.DataFrame:
    '''
    Function that takes the order dataframe and the menu dataframe to return the performance dataframe.

    :Param: o_df: pd.DataFrame
    ---------
        Order dataframe generated by 'build_order_df' function

    :Param: m_df: pd.DataFrame
    ---------
        Menu dataframe generated by 'build_menu_df' function

    :Returns: pd.DataFrame
    ---------
        Schema:
            'name','net_revenue', 'quantity', 'expected_rev', 'diff',
            'avg_diff', 'expected_rev (usd)', 'net_revenue (usd)',
            'avg_diff (usd)', 'dollar_yield_per_min'

    '''
    # derives the name, total paid, and quantity for each item in every order
    # multiplies the paid per unit by the quantity to extract full revenue by item
    # each List item should be a Tuple T where T[0] == name,
    # T[1] == total rev for item in order and T[2] == quantity ordered per item
    menu_perf_data = (list(map(
        lambda x: (
            x.get('name'), (x.get('paid_per_unit', 0) * x.get('quantity', 0)), x.get('quantity', 0)
        ), items)) for items in list(o_df['items']))

    # output of perf data is shaped List[Union[Tuple[str, int, int], List[Tuple[str, int, int]]]]
    # Need to flatten it so that we can put it in a dataframe and run some grouping logic
    flat_menu_perf_data = list(chain.from_iterable(menu_perf_data))

    # Make a dataframe from the flattened performance data
    menu_perf_df = (
        pd.DataFrame(
            flat_menu_perf_data,
            columns=['name', 'net_revenue', 'quantity'])
        .groupby('name')
        .sum()
        .reset_index(drop=False)
    )

    # merges menu dataframe with the performance dataframe so we can measure
    # expected item performance against actual item performance by revenue
    merged = m_df.merge(menu_perf_df, how='inner', on='name')

    merged['expected_rev'] = merged.apply(lambda row: row['price_per_unit'] * row['quantity'], axis=1)
    merged['diff'] = merged.apply(lambda row: row['net_revenue'] - row['expected_rev'], axis=1)

    # Difference between the actual revenue and expected revenue divided by total
    # number of times a particular item was ordered. (Track tips, refunds, etc etc)
    merged['avg_diff'] = merged.apply(lambda row: row['diff'] / row['quantity'], axis=1)

    # USD representations of these columns (divide by 100 for cents -> dollars)
    merged['expected_rev (usd)'] = merged['expected_rev'].apply(lambda x: x / 100)
    merged['net_revenue (usd)'] = merged['net_revenue'].apply(lambda x: x / 100)
    merged['avg_diff (usd)'] = merged['avg_diff'].apply(lambda x: x / 100)

    # Get the average net revenue per item and divide it by the cook time in minutes
    # to track if certain items with low cost and long cooktimes can be removed from the menu
    merged['dollar yield per min'] = merged.apply(
        lambda row: round((row['net_revenue (usd)'] / row['quantity']) / (row['cook_time'] / 60), 2),
        axis=1
    )

    # Columns not needed
    merged = merged.drop('cook_time', axis=1).drop('price_per_unit', axis=1)

    return merged


def build_ngram_df(
    ngrams: List[T],
    time_map: Dict[str, int] = {},
    price_map: Dict[str, int] = {},
) -> pd.DataFrame:
    '''
        Function that generates a dataFrame from a list of `n-grams`
        :Param: ngrams: List[T]
        -------
            List of nested Tuples of length N and frequency of occurrence

        :Param: price_map: Dict[str, int]
        -------
            Reference to mapping of menu item to price

        :Param: time_map: Dict[str, int]
        -------
            Reference to mapping of menu item to time

        :Returns: pd.DataFrame
        --------
            Schema:
                'combo', 'frequency', 'price', 'time', 'time saved', 'time saved (min)', 'time (min)', 'price (usd)'
    '''

    df = (pd.DataFrame
          .from_dict(get_ngram_frequency(ngrams), orient='index')
          .reset_index(drop=False)
          .rename(columns={'index': 'combo', 0: 'frequency'}))

    df['price'] = df.apply(lambda row: sum([price_map.get(el, tuple()) for el in row['combo']]), axis=1)

    # Time to cook the dishes in parallel
    df['time'] = df.apply(lambda row: max([price_map.get(el, tuple()) for el in row['combo']]), axis=1)

    # Time saved from not cooking items separately
    df['time saved'] = df.apply(
        lambda row: sum([time_map.get(el, tuple()) for el in row['combo']]) - max([time_map.get(el, tuple()) for el in row['combo']]),
        axis=1)

    df['time saved (min)'] = df['time saved'].apply(lambda x: x / 60)
    df['time (min)'] = df['time'].apply(lambda x: x / 60)
    df['price (usd)'] = df['price'].apply(lambda x: x / 100)

    return df.sort_values(by='frequency', ascending=False)


def gen_mappings():
    '''Function that generates the time mapping and price mapping dictionaries'''
    i_df = build_menu_df()
    # Dict to map recipes to cook times and recipes to price per unit
    time_mapping = {v['name']: v['cook_time'] for _, v in i_df.iterrows()}
    price_mapping = {v['name']: v['price_per_unit']
                     for _, v in i_df.iterrows()}

    return time_mapping, price_mapping
